{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the LateX cutflow tables\n",
    "- Will load the pkl files that contain the cutflows and the sumgenweight\n",
    "- Will scale the events by the cross section\n",
    "- Will save the yields in a dictionnary called ```cutflows -> Dict()```\n",
    "- Will make the LateX table using the function ```make_composition_table()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import pickle as pkl\n",
    "import sys\n",
    "\n",
    "import hist as hist2\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow\n",
    "import pyarrow.parquet as pq\n",
    "import yaml\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path\n",
    "sys.path.append(\"../python/\")\n",
    "\n",
    "import utils\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "plt.rcParams.update({\"font.size\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ele': {'Run2': 137640.0,\n",
       "  '2016APV': 19492.72,\n",
       "  '2016': 16809.96,\n",
       "  '2017': 41476.02,\n",
       "  '2018': 59816.23},\n",
       " 'mu': {'Run2': 137640.0,\n",
       "  '2016APV': 19436.16,\n",
       "  '2016': 16810.81,\n",
       "  '2017': 41475.26,\n",
       "  '2018': 59781.96},\n",
       " 'lep': {'Run2': 137640.0,\n",
       "  '2016APV': 19436.16,\n",
       "  '2016': 16810.81,\n",
       "  '2017': 41475.26,\n",
       "  '2018': 59781.96},\n",
       " 'had': {'Run2': 137640.0,\n",
       "  '2016APV': 19436.16,\n",
       "  '2016': 16810.81,\n",
       "  '2017': 41475.26,\n",
       "  '2018': 59781.96}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get lumi\n",
    "with open(\"../fileset/luminosity.json\") as f:\n",
    "    luminosity = json.load(f)\n",
    "    \n",
    "luminosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lumi(years, channels):\n",
    "    lum_ = 0\n",
    "    for year in years:\n",
    "        lum = 0\n",
    "        for ch in channels:\n",
    "            lum += luminosity[ch][year] / 1000.0\n",
    "\n",
    "        lum_ += lum / len(channels)    \n",
    "    return lum_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read cutflows from pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cutflow(pkl_files, year, ch, sample, is_data):\n",
    "    \"\"\"Get cutflow from metadata but multiply by xsec-weight.\"\"\"\n",
    "\n",
    "    with open(\"../fileset/luminosity.json\") as f:\n",
    "        luminosity = json.load(f)[ch][year]\n",
    "\n",
    "    xsec_weight = utils.get_xsecweight(pkl_files, year, sample, is_data, luminosity)\n",
    "\n",
    "    cuts = [\n",
    "        \"sumgenweight\",\n",
    "        \"Trigger\",\n",
    "        \"METFilters\",\n",
    "        \"OneLep\",\n",
    "        \"NoTaus\",\n",
    "        \"AtLeastOneFatJet\",\n",
    "        \"CandidateJetpT\",\n",
    "        \"LepInJet\",\n",
    "        \"JetLepOverlap\",\n",
    "        \"dPhiJetMET\",\n",
    "        \"MET\",\n",
    "    ]\n",
    "\n",
    "    if year == \"2018\":\n",
    "        cuts += [\"HEMCleaning\"]\n",
    "\n",
    "    evyield = dict.fromkeys(cuts, 0)\n",
    "    for ik, pkl_file in enumerate(pkl_files):\n",
    "        with open(pkl_file, \"rb\") as f:\n",
    "            metadata = pkl.load(f)\n",
    "\n",
    "        cutflows = metadata[sample][year][\"cutflows\"][ch]\n",
    "\n",
    "        for key in evyield.keys():\n",
    "\n",
    "            if key == \"sumgenweight\":\n",
    "                evyield[key] += metadata[sample][year][key] * xsec_weight\n",
    "            else:\n",
    "                evyield[key] += cutflows[key] * xsec_weight\n",
    "    return evyield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a cut from the parquets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is your configuration. specefy which channels, years, samples, and directory of pkl files to use.\n",
    "channels = [\n",
    "    \"ele\", \n",
    "    \"mu\",\n",
    "]\n",
    "years = [\n",
    "#     \"2018\", \n",
    "    \"2017\",\n",
    "#     \"2016\", \n",
    "#     \"2016APV\",\n",
    "]\n",
    "\n",
    "samples = [\n",
    "    \"ggF\", \n",
    "    \"VBF\",  \n",
    "    \"WH\",\n",
    "    \"ZH\",    \n",
    "    \"ttH\",\n",
    "    \"WJetsLNu\",\n",
    "    \"TTbar\",\n",
    "    \"SingleTop\",\n",
    "    \"Diboson\",\n",
    "    \"EWKvjets\",\n",
    "    \"DYJets\",\n",
    "    \"WZQQ\",\n",
    "    \"Data\",\n",
    "]\n",
    "\n",
    "samples_dir = {\n",
    "#     \"2016\":    \"../eos/Oct10_hww_2016\",\n",
    "#     \"2016APV\": \"../eos/Oct10_hww_2016APV\",    \n",
    "#     \"2017\":    \"../eos/Oct10_hww_2017\",    \n",
    "#     \"2018\":    \"../eos/Oct10_hww_2018\",\n",
    "    \n",
    "    \"2016\":    \"../eos/hww/Dec20_hww_2016\",\n",
    "    \"2016APV\": \"../eos/hww/Dec20_hww_2016APV\",    \n",
    "    \"2017\":    \"../eos/hww/Dec20_hww_2017\",\n",
    "#     \"2017\":    \"../eos/hww/Jun5_hww_2017\",\n",
    "    \"2018\":    \"../eos/hww/Dec20_hww_2018\",    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 2017\n",
      "  ele channel\n",
      "  mu channel\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cutflows = {}\n",
    "for year in years:\n",
    "    print(f\"Processing year {year}\")\n",
    "    \n",
    "    cutflows[year] = {}\n",
    "    \n",
    "    for ch in channels:\n",
    "        print(f\"  {ch} channel\")\n",
    "        cutflows[year][ch] = {}\n",
    "\n",
    "        condor_dir = os.listdir(samples_dir[year])\n",
    "\n",
    "        for sample in condor_dir:\n",
    "\n",
    "            # first: check if the sample is in one of combine_samples_by_name\n",
    "            sample_to_use = None\n",
    "            for key in utils.combine_samples_by_name:\n",
    "                if key in sample:\n",
    "                    sample_to_use = utils.combine_samples_by_name[key]\n",
    "                    break\n",
    "\n",
    "            # second: if not, combine under common label\n",
    "            if sample_to_use is None:\n",
    "                for key in utils.combine_samples:\n",
    "                    if key in sample:\n",
    "                        sample_to_use = utils.combine_samples[key]\n",
    "                        break\n",
    "                    else:\n",
    "                        sample_to_use = sample\n",
    "\n",
    "            if sample_to_use not in samples:\n",
    "                continue\n",
    "\n",
    "            is_data = False\n",
    "            if sample_to_use == \"Data\":\n",
    "                is_data = True\n",
    "\n",
    "            out_files = f\"{samples_dir[year]}/{sample}/outfiles/\"\n",
    "            pkl_files = glob.glob(f\"{out_files}/*.pkl\")\n",
    "\n",
    "            if len(pkl_files) == 0:\n",
    "                continue\n",
    "\n",
    "            parquet_files = glob.glob(f\"{out_files}/*_{ch}.parquet\")\n",
    "            \n",
    "            try:\n",
    "                data = pd.read_parquet(parquet_files)\n",
    "            except pyarrow.lib.ArrowInvalid:\n",
    "                continue\n",
    "\n",
    "            if len(data) == 0:\n",
    "                continue\n",
    "    \n",
    "            if sample_to_use not in cutflows[year][ch].keys():\n",
    "                cutflows[year][ch][sample_to_use] = get_cutflow(pkl_files, year, ch, sample, is_data)\n",
    "            else:\n",
    "                temp = get_cutflow(pkl_files, year, ch, sample, is_data)\n",
    "                for key in cutflows[year][ch][sample_to_use]:\n",
    "                    cutflows[year][ch][sample_to_use][key] += temp[key]\n",
    "            \n",
    "    print(f\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['EWKvjets', 'WH', 'TTbar', 'SingleTop', 'ggF', 'DYJets', 'Data', 'Diboson', 'WZQQ', 'ttH', 'WJetsLNu', 'VBF', 'ZH'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = cutflows[\"2017\"][\"ele\"].keys()  # samples\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing 2017, ele channel\n",
      "INFO:root:Processing 2017, mu channel\n"
     ]
    }
   ],
   "source": [
    "from make_stacked_hists import make_events_dict\n",
    "\n",
    "presel = {\n",
    "        \"mu\": {\n",
    "#             \"fj_mass\": \"fj_mass>40\",\n",
    "#             \"THWW>0.75\": \"THWW>0.750\",\n",
    "        },\n",
    "        \"ele\": {\n",
    "#             \"fj_mass\": \"fj_mass>40\",\n",
    "#             \"THWW>0.75\": \"THWW>0.750\",\n",
    "        },\n",
    "}\n",
    "\n",
    "THWW_path = \"../ParT_Finetuned/v35_30/model.onnx\"\n",
    "\n",
    "events_dict = make_events_dict(years, channels, samples_dir, samples, presel, THWW_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the cut to the cutflow dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "presel = {\n",
    "        \"mu\": {\n",
    "            \"fj_mass\": \"fj_mass>40\",\n",
    "            \"THWW>0.75\": \"fj_mass>40 & THWW>0.75\",\n",
    "        },\n",
    "        \"ele\": {\n",
    "            \"fj_mass\": \"fj_mass>40\",\n",
    "            \"THWW>0.75\": \"fj_mass>40 & THWW>0.75\",\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in channels:\n",
    "    for cut, sel in list(presel[ch].items()):\n",
    "        for sample in samples:\n",
    "            for year in years:\n",
    "\n",
    "                df = events_dict[year][ch][sample]\n",
    "                df = df.query(sel)\n",
    "                \n",
    "                w = df[\"nominal\"]\n",
    "\n",
    "                cutflows[year][ch][sample][cut] = w.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sumgenweight': 2574369388.2,\n",
       " 'Trigger': 262528762.08510852,\n",
       " 'METFilters': 262483609.5058111,\n",
       " 'OneLep': 262404792.80707616,\n",
       " 'NoTaus': 249460139.5353195,\n",
       " 'AtLeastOneFatJet': 1269172.7935222525,\n",
       " 'CandidateJetpT': 557102.9950070238,\n",
       " 'LepInJet': 195648.31646448522,\n",
       " 'JetLepOverlap': 69495.70367106168,\n",
       " 'dPhiJetMET': 47434.306849256645,\n",
       " 'MET': 44095.650583831215,\n",
       " 'fj_mass': 33762.98047363191,\n",
       " 'THWW>0.75': 1202.2920209445638}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutflows[\"2017\"][\"mu\"][\"WJetsLNu\"]     # take a quick look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine different channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_channels(cutflows):\n",
    "\n",
    "    # combine both channels\n",
    "    cutflows_new = {}\n",
    "    for year in cutflows.keys():\n",
    "        cutflows_new[year] = {}\n",
    "        cutflows_new[year][\"lep\"] = {}\n",
    "        \n",
    "        for ch in [\"mu\", \"ele\"]:\n",
    "            for sample in cutflows[year][ch]:\n",
    "                                \n",
    "                if sample not in cutflows_new[year][\"lep\"]:\n",
    "                    cutflows_new[year][\"lep\"][sample] = {}\n",
    "                \n",
    "                for cut in cutflows[year][ch][sample]:\n",
    "                    \n",
    "                    if (year != \"2018\") and (cut == \"HEMCleaning\"):\n",
    "                        continue\n",
    "                    \n",
    "                    if cut not in cutflows_new[year][\"lep\"][sample]:\n",
    "                        cutflows_new[year][\"lep\"][sample][cut] = cutflows[year][ch][sample][cut]\n",
    "                    else:\n",
    "                        cutflows_new[year][\"lep\"][sample][cut] += cutflows[year][ch][sample][cut]\n",
    "        cutflows[year] = {**cutflows[year], **cutflows_new[year]}\n",
    "        \n",
    "    return cutflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutflows = combine_channels(cutflows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ele', 'mu', 'lep'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutflows[\"2018\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutflows[\"2018\"][\"ele\"][\"WJetsLNu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutflows[\"2018\"][\"mu\"][\"WJetsLNu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutflows[\"2018\"][\"lep\"][\"WJetsLNu\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine different years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_years(cutflows):\n",
    "    \"\"\"Will remove the HEM cleaning cutflow from 2018 first.\"\"\"\n",
    "    \n",
    "    whatever_year = list(cutflows.keys())[0]\n",
    "    channels = cutflows[whatever_year].keys()\n",
    "    \n",
    "    # combine all years\n",
    "    cutflows_new = {}\n",
    "    cutflows_new[\"Run2\"] = {}\n",
    "    \n",
    "    for ch in channels:\n",
    "        cutflows_new[\"Run2\"][ch] = {}\n",
    "        \n",
    "        for year in cutflows:\n",
    "            for sample in cutflows[year][ch]:\n",
    "                \n",
    "                if sample not in cutflows_new[\"Run2\"][ch]:\n",
    "                    cutflows_new[\"Run2\"][ch][sample] = {}\n",
    "\n",
    "                for cut in cutflows[year][ch][sample]:\n",
    "                    if \"HEM\" in cut:\n",
    "                        continue\n",
    "                    if cut not in cutflows_new[\"Run2\"][ch][sample]:\n",
    "                        cutflows_new[\"Run2\"][ch][sample][cut] = cutflows[year][ch][sample][cut]\n",
    "                    else:\n",
    "                        cutflows_new[\"Run2\"][ch][sample][cut] += cutflows[year][ch][sample][cut]\n",
    "\n",
    "    cutflows = {**cutflows, **cutflows_new}\n",
    "\n",
    "    return cutflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutflows = combine_years(cutflows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['WJetsLNu', 'EWKvjets', 'WH', 'TTbar', 'SingleTop', 'ggF', 'DYJets', 'Data', 'Diboson', 'WZQQ', 'ttH', 'VBF', 'ZH'])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutflows[\"2017\"][\"ele\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2017', 'Run2'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutflows.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ele', 'mu', 'lep'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutflows[\"Run2\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine non-dominant backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine non-dominant backgrounds under others\n",
    "dominant_bkgs = [\"WJetsLNu\", \"TTbar\"]\n",
    "signals = [\"ggF\", \"VBF\", \"WH\", \"ZH\", \"ttH\"]\n",
    "\n",
    "for year in cutflows:\n",
    "    for ch in cutflows[year]:\n",
    "        cutflows[year][ch][\"Others\"] = dict.fromkeys(cutflows[year][ch][\"WJetsLNu\"], 0)\n",
    "        for sample in cutflows[year][ch]:\n",
    "            if sample == \"Data\":\n",
    "                continue\n",
    "            if sample not in signals+dominant_bkgs:\n",
    "                for cut in cutflows[year][ch][sample]:\n",
    "                    cutflows[year][ch][\"Others\"][cut] += cutflows[year][ch][sample][cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['EWKvjets', 'WH', 'TTbar', 'SingleTop', 'ggF', 'DYJets', 'Data', 'Diboson', 'WZQQ', 'ttH', 'WJetsLNu', 'VBF', 'ZH', 'Others'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutflows[\"2017\"][\"ele\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sumgenweight': 504923757.8414528,\n",
       " 'Trigger': 70230387.808001,\n",
       " 'METFilters': 70200411.81948991,\n",
       " 'OneLep': 46194136.59237416,\n",
       " 'NoTaus': 42957715.67864163,\n",
       " 'AtLeastOneFatJet': 1239221.4055518333,\n",
       " 'CandidateJetpT': 570697.1902661477,\n",
       " 'LepInJet': 280836.05979165446,\n",
       " 'JetLepOverlap': 106246.29007646533,\n",
       " 'dPhiJetMET': 63896.01737911475,\n",
       " 'MET': 55330.25217421119,\n",
       " 'fj_mass': 41640.55400653274,\n",
       " 'THWW>0.75': 739.990689612537}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutflows[\"2017\"][\"lep\"][\"Others\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LateX cutflow table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts = [\n",
    "    \"sumgenweight\",\n",
    "    \"Trigger\",\n",
    "    \"METFilters\",\n",
    "    \"OneLep\",        \n",
    "    \"NoTaus\",\n",
    "    \"AtLeastOneFatJet\",\n",
    "    \"CandidateJetpT\",\n",
    "    \"LepInJet\",\n",
    "    \"JetLepOverlap\",\n",
    "    \"dPhiJetMET\",\n",
    "    \"MET\",\n",
    "    \"HEMCleaning\",\n",
    "]\n",
    "\n",
    "for cut in presel[\"mu\"]:\n",
    "    cuts += [cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_to_label = {\n",
    "    \"sumgenweight\": \"sumgenweight\",        \n",
    "    \"HEMCleaning\": \"HEMCleaning\",    \n",
    "    \"Trigger\": \"Trigger\",\n",
    "    \"METFilters\": \"METFilters\",\n",
    "    \"OneLep\": \"n Leptons = 1\",\n",
    "    \"NoTaus\": \"n Taus = 0\",\n",
    "    \"AtLeastOneFatJet\": r\"n FatJets $>=$ 1\",\n",
    "    \"CandidateJetpT\": r\"j $p_T > 250$GeV\",\n",
    "    \"LepInJet\": r\"$\\Delta R(j, \\ell) < 0.8$\",\n",
    "    \"JetLepOverlap\": r\"$\\Delta R(j, \\ell) > 0.03$\",\n",
    "    \"dPhiJetMET\": r\"$\\Delta \\phi(\\mathrm{MET}, j)<1.57$\",\n",
    "    \"MET\": r\"$\\mathrm{MET}>20$\",\n",
    "    \n",
    "    \"None\": \"None\",\n",
    "\n",
    "    \"fj_mass\": r\"j $\\mathrm{softdrop} > 40$GeV\",\n",
    "    \n",
    "    \"THWW>0.75\": r\"$\\ensuremath{T_{\\text{HWW}}^{\\ell\\nu qq}} > 0.75$\",\n",
    "} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_to_latex = {\n",
    "    \"WJetsLNu\": \"$\\PW(\\Pell\\PGn)$+\",\n",
    "    \"TTbar\": \"\\\\ttbar\",\n",
    "    \"Others\": \"Other MC\",\n",
    "\n",
    "    \"ggF\": \"ggF\",\n",
    "    \"VBF\": \"VBF\",\n",
    "    \"WH\": \"WH\",\n",
    "    \"ZH\": \"ZH\",    \n",
    "    \"ttH\": \"$t\\\\bar{t}H$\",    \n",
    "    \n",
    "    \"Data\": \"Data\",\n",
    "}\n",
    "\n",
    "def make_latex_cutflow_table(cutflows_dict, year, ch, add_data=False, add_sumgenweight=False):\n",
    "    \"\"\"Will use the cutflows dictionary to make the LateX table we have in the AN.\"\"\"\n",
    "    \n",
    "    samples_bkg = [\"WJetsLNu\", \"TTbar\", \"Others\"]\n",
    "    samples_sig = [\"ggF\",\"VBF\", \"WH\", \"ZH\", \"ttH\"]\n",
    "\n",
    "    ### backgrounds\n",
    "    headers = [parquet_to_latex[s] for s in samples_bkg]\n",
    "    \n",
    "    textabular = f\"l{'r'*len(headers)}\"\n",
    "    textabular += \"|r\"\n",
    "    \n",
    "    texheader = \"\\\\textbf{Inclusive Selection}\" + \" & \" + \" & \".join(headers) + \" & Total MC \"\n",
    "    if add_data:\n",
    "        textabular += \"|r\"\n",
    "        texheader += \"& Data \"\n",
    "    texheader += \"\\\\\\\\\"\n",
    "    texdata = \"\\\\hline\\n\"\n",
    "    \n",
    "    data = dict()\n",
    "    \n",
    "    for cut in cuts: \n",
    "        if (year != \"2018\") and (cut == \"HEMCleaning\"):\n",
    "            continue\n",
    "            \n",
    "        if not add_sumgenweight and cut == \"sumgenweight\":\n",
    "            continue\n",
    "    \n",
    "        data[cut] = []\n",
    "\n",
    "        for sample in samples_bkg:            \n",
    "            data[cut].append(round(cutflows_dict[year][ch][sample][cut]))\n",
    "            \n",
    "        totalmc = 0\n",
    "        for sample in (samples_bkg + samples_sig):\n",
    "            totalmc += round(cutflows_dict[year][ch][sample][cut])\n",
    "            \n",
    "        data[cut].append(totalmc)\n",
    "        \n",
    "        if add_data:\n",
    "            data[cut].append(round(cutflows_dict[year][ch][\"Data\"][cut]))\n",
    "\n",
    "    for label in data:\n",
    "        if label == \"z\":\n",
    "            texdata += \"\\\\hline\\n\"\n",
    "        texdata += f\"{cut_to_label[label]} & {' & '.join(map(str,data[label]))} \\\\\\\\\\n\"\n",
    "        \n",
    "    texdata += \"\\\\hline\\n\"    \n",
    "\n",
    "    ### signal\n",
    "    headers2 = [parquet_to_latex[s] for s in samples_sig]\n",
    "    texheader2 = \" & \" + \" & \".join(headers2) + \"\\\\\\\\\"\n",
    "    texdata2 = \"\\\\hline\\n\"\n",
    "\n",
    "    textabular2 = f\"l{'r'*len(headers2)}\"\n",
    "    \n",
    "    data = dict()\n",
    "    for cut in cuts:\n",
    "        if (year != \"2018\") and (cut == \"HEMCleaning\"):\n",
    "            continue\n",
    "            \n",
    "        data[cut] = []\n",
    "\n",
    "        for sample in samples_sig:\n",
    "            data[cut].append(round(cutflows_dict[year][ch][sample][cut]))\n",
    "        \n",
    "    for label in data:\n",
    "        if label == \"z\":\n",
    "            texdata += \"\\\\hline\\n\"\n",
    "        texdata2 += f\"{cut_to_label[label]} & {' & '.join(map(str,data[label]))} \\\\\\\\\\n\"    \n",
    "\n",
    "    # make table\n",
    "    print(\"\\\\begin{table}[!htp]\")\n",
    "    print(\"\\\\begin{center}\")\n",
    "    \n",
    "    print(\"\\\\begin{tabular}{\"+textabular+\"}\")\n",
    "    print(texheader)\n",
    "    print(texdata,end=\"\")\n",
    "    print(\"\\\\end{tabular}\")\n",
    "\n",
    "    print(\"\\\\begin{tabular}{\"+textabular2+\"}\")\n",
    "    print(texheader2)\n",
    "    print(texdata2,end=\"\")\n",
    "    print(\"\\\\end{tabular}\")\n",
    "    \n",
    "    \n",
    "    if ch == \"lep\":\n",
    "        print(\"\\\\caption{Event yield of \" + year + \" Monte Carlo samples normalized to \" + str(round(get_lumi([year], [ch]))) + \"\\\\fbinv.}\")        \n",
    "    else:\n",
    "        print(\"\\\\caption{Event yield of \" + ch + \" channel \" + year + \" Monte Carlo samples normalized to \" + str(round(get_lumi([year], [ch]))) + \"\\\\fbinv.}\")\n",
    "        \n",
    "    print(\"\\\\label{sel-tab-cutflow\" + year + \"}\")\n",
    "    print(\"\\\\end{center}\")\n",
    "    print(\"\\\\end{table}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[!htp]\n",
      "\\begin{center}\n",
      "\\begin{tabular}{lrrr|r|r}\n",
      "\\textbf{Inclusive Selection} & $\\PW(\\Pell\\PGn)$+ & \\ttbar & Other MC & Total MC & Data \\\\\n",
      "\\hline\n",
      "sumgenweight & 5148785950 & 68995474 & 504923758 & 5723211346 & 1202391493 \\\\\n",
      "Trigger & 422374980 & 6978344 & 70230388 & 499621553 & 619791460 \\\\\n",
      "METFilters & 422304875 & 6973776 & 70200412 & 499516890 & 619630992 \\\\\n",
      "n Leptons = 1 & 356832781 & 5893155 & 46194137 & 408952559 & 442103860 \\\\\n",
      "n Taus = 0 & 343888128 & 4704050 & 42957716 & 391578810 & 424640213 \\\\\n",
      "n FatJets $>=$ 1 & 2360858 & 882238 & 1239221 & 4484727 & 5032388 \\\\\n",
      "j $p_T > 250$GeV & 1033120 & 448262 & 570697 & 2053353 & 2000795 \\\\\n",
      "$\\Delta R(j, \\ell) < 0.8$ & 376712 & 198780 & 280836 & 857066 & 993318 \\\\\n",
      "$\\Delta R(j, \\ell) > 0.03$ & 126912 & 171166 & 106246 & 405005 & 456364 \\\\\n",
      "$\\Delta \\phi(\\mathrm{MET}, j)<1.57$ & 85866 & 107940 & 63896 & 258163 & 252747 \\\\\n",
      "$\\mathrm{MET}>20$ & 79598 & 101745 & 55330 & 237101 & 229103 \\\\\n",
      "j $\\mathrm{softdrop} > 40$GeV & 60400 & 79700 & 41641 & 181922 & 192491 \\\\\n",
      "$\\ensuremath{T_{\\text{HWW}}^{\\ell\\nu qq}} > 0.75$ & 2175 & 850 & 740 & 3825 & 3512 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lrrrrr}\n",
      " & ggF & VBF & WH & ZH & $t\\bar{t}H$\\\\\n",
      "\\hline\n",
      "sumgenweight & 381489 & 67042 & 24335 & 15669 & 17629 \\\\\n",
      "Trigger & 27710 & 4034 & 2398 & 1207 & 2492 \\\\\n",
      "METFilters & 27704 & 4031 & 2397 & 1206 & 2489 \\\\\n",
      "n Leptons = 1 & 24288 & 3451 & 1952 & 897 & 1898 \\\\\n",
      "n Taus = 0 & 22393 & 2904 & 1570 & 737 & 1312 \\\\\n",
      "n FatJets $>=$ 1 & 1251 & 296 & 185 & 82 & 596 \\\\\n",
      "j $p_T > 250$GeV & 646 & 135 & 96 & 44 & 353 \\\\\n",
      "$\\Delta R(j, \\ell) < 0.8$ & 424 & 78 & 46 & 26 & 164 \\\\\n",
      "$\\Delta R(j, \\ell) > 0.03$ & 404 & 73 & 31 & 23 & 150 \\\\\n",
      "$\\Delta \\phi(\\mathrm{MET}, j)<1.57$ & 281 & 53 & 21 & 13 & 93 \\\\\n",
      "$\\mathrm{MET}>20$ & 260 & 49 & 19 & 12 & 88 \\\\\n",
      "j $\\mathrm{softdrop} > 40$GeV & 80 & 34 & 15 & 9 & 43 \\\\\n",
      "$\\ensuremath{T_{\\text{HWW}}^{\\ell\\nu qq}} > 0.75$ & 32 & 15 & 5 & 3 & 5 \\\\\n",
      "\\end{tabular}\n",
      "\\caption{Event yield of 2017 Monte Carlo samples normalized to 41\\fbinv.}\n",
      "\\label{sel-tab-cutflow2017}\n",
      "\\end{center}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "make_latex_cutflow_table(cutflows, \"2017\", \"lep\", add_data=True, add_sumgenweight=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea-env",
   "language": "python",
   "name": "coffea-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
