{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import uproot\n",
    "from coffea import nanoevents, processor\n",
    "from coffea.nanoevents import BaseSchema, NanoAODSchema, NanoEventsFactory\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import pickle as pkl\n",
    "import shutil\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from typing import List, Optional\n",
    "\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from coffea import processor\n",
    "from coffea.analysis_tools import PackedSelection, Weights\n",
    "from coffea.nanoevents.methods import candidate, vector\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Found duplicate branch \")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "np.seterr(invalid=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hww1.root  hww2.root\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../rootfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of events per file is 98400\n"
     ]
    }
   ],
   "source": [
    "# load a root file into coffea-friendly NanoAOD structure\n",
    "import uproot\n",
    "f = uproot.open(f\"../rootfiles/hww1.root\")\n",
    "num = f['Events'].num_entries   ### checks number of events per file \n",
    "print(f'number of events per file is {num}')\n",
    "\n",
    "events = nanoevents.NanoEventsFactory.from_root(f, \"Events\").events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_p4(cand):\n",
    "    return ak.zip(\n",
    "        {\n",
    "            \"pt\": cand.pt,\n",
    "            \"eta\": cand.eta,\n",
    "            \"phi\": cand.phi,\n",
    "            \"mass\": cand.mass,\n",
    "            \"charge\": cand.charge,\n",
    "        },\n",
    "        with_name=\"PtEtaPhiMCandidate\",\n",
    "        behavior=candidate.behavior,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make selections\n",
    "nevents = len(events)\n",
    "\n",
    "# define muon objects\n",
    "loose_muons = (\n",
    "    (((events.Muon.pt > 30) & (events.Muon.pfRelIso04_all < 0.25)) |\n",
    "     (events.Muon.pt > 55))\n",
    "    & (np.abs(events.Muon.eta) < 2.4)\n",
    "    & (events.Muon.looseId)\n",
    ")\n",
    "n_loose_muons = ak.sum(loose_muons, axis=1)\n",
    "\n",
    "good_muons = (\n",
    "    (events.Muon.pt > 28)\n",
    "    & (np.abs(events.Muon.eta) < 2.4)\n",
    "    & (np.abs(events.Muon.dz) < 0.1)\n",
    "    & (np.abs(events.Muon.dxy) < 0.05)\n",
    "    & (events.Muon.sip3d <= 4.0)\n",
    "    & events.Muon.mediumId\n",
    ")\n",
    "n_good_muons = ak.sum(good_muons, axis=1)\n",
    "\n",
    "# define electron objects\n",
    "loose_electrons = (\n",
    "    (((events.Electron.pt > 38) & (events.Electron.pfRelIso03_all < 0.25)) |\n",
    "     (events.Electron.pt > 120))\n",
    "    & ((np.abs(events.Electron.eta) < 1.44) | (np.abs(events.Electron.eta) > 1.57))\n",
    "    & (events.Electron.cutBased >= events.Electron.LOOSE)\n",
    ")\n",
    "n_loose_electrons = ak.sum(loose_electrons, axis=1)\n",
    "\n",
    "good_electrons = (\n",
    "    (events.Electron.pt > 38)\n",
    "    & ((np.abs(events.Electron.eta) < 1.44) | (np.abs(events.Electron.eta) > 1.57))\n",
    "    & (np.abs(events.Electron.dz) < 0.1)\n",
    "    & (np.abs(events.Electron.dxy) < 0.05)\n",
    "    & (events.Electron.sip3d <= 4.0)\n",
    "    & (events.Electron.mvaFall17V2noIso_WP90)\n",
    ")\n",
    "n_good_electrons = ak.sum(good_electrons, axis=1)\n",
    "\n",
    "# leading lepton\n",
    "goodleptons = ak.concatenate([events.Muon[good_muons], events.Electron[good_electrons]], axis=1)\n",
    "goodleptons = goodleptons[ak.argsort(goodleptons.pt, ascending=False)]\n",
    "candidatelep = ak.firsts(goodleptons)\n",
    "\n",
    "# candidate leptons\n",
    "candidatelep_p4 = build_p4(candidatelep)\n",
    "\n",
    "# MET\n",
    "met = events.MET\n",
    "mt_lep_met = np.sqrt(\n",
    "    2. * candidatelep_p4.pt * met.pt * (ak.ones_like(met.pt) - np.cos(candidatelep_p4.delta_phi(met)))\n",
    ")\n",
    "\n",
    "# JETS\n",
    "goodjets = events.Jet[\n",
    "    (events.Jet.pt > 30)\n",
    "    & (abs(events.Jet.eta) < 2.5)\n",
    "    & events.Jet.isTight\n",
    "    & (events.Jet.puId > 0)\n",
    "]\n",
    "ht = ak.sum(goodjets.pt, axis=1)\n",
    "\n",
    "# FATJETS\n",
    "fatjets = events.FatJet\n",
    "\n",
    "good_fatjets = (\n",
    "    (fatjets.pt > 200)\n",
    "    & (abs(fatjets.eta) < 2.5)\n",
    "    & fatjets.isTight\n",
    ")\n",
    "n_fatjets = ak.sum(good_fatjets, axis=1)\n",
    "\n",
    "good_fatjets = fatjets[good_fatjets]\n",
    "good_fatjets = good_fatjets[ak.argsort(good_fatjets.pt, ascending=False)]\n",
    "\n",
    "# for lep channel: first clean jets and leptons by removing overlap, then pick candidate_fj closest to the lepton\n",
    "lep_in_fj_overlap_bool = good_fatjets.delta_r(candidatelep_p4) > 0.1\n",
    "good_fatjets = good_fatjets[lep_in_fj_overlap_bool]\n",
    "fj_idx_lep = ak.argmin(good_fatjets.delta_r(candidatelep_p4), axis=1, keepdims=True)\n",
    "candidatefj = ak.firsts(good_fatjets[fj_idx_lep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Array [None, None, None, ... None, None, None] type='98400 * ?float32[parameter...'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidatefj.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from coffea.nanoevents.methods.base import NanoEventsArray\n",
    "\n",
    "def get_pfcands_features(\n",
    "    tagger_vars: dict,\n",
    "    preselected_events: NanoEventsArray,\n",
    "    fj_idx_lep,\n",
    "    fatjet_label: str = \"FatJetAK15\",\n",
    "    pfcands_label: str = \"FatJetPFCands\",\n",
    "    normalize: bool = True,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extracts the pf_candidate features specified in the ``tagger_vars`` dict from the\n",
    "    ``preselected_events`` and returns them as a dict of numpy arrays\n",
    "    \"\"\"\n",
    "\n",
    "    feature_dict = {}\n",
    "\n",
    "    jet = ak.firsts(preselected_events[fatjet_label][fj_idx_lep])\n",
    "\n",
    "    msk = preselected_events[pfcands_label].jetIdx == ak.firsts(fj_idx_lep)\n",
    "    jet_ak_pfcands = preselected_events[pfcands_label][msk]\n",
    "    jet_pfcands = preselected_events.PFCands[jet_ak_pfcands.pFCandsIdx]\n",
    "\n",
    "    # sort them by pt\n",
    "    pfcand_sort = ak.argsort(jet_pfcands.pt, ascending=False)\n",
    "    jet_pfcands = jet_pfcands[pfcand_sort]\n",
    "\n",
    "    # negative eta jets have -1 sign, positive eta jets have +1\n",
    "    eta_sign = ak.ones_like(jet_pfcands.eta)\n",
    "    eta_sign = eta_sign * (ak.values_astype(jet.eta > 0, int) * 2 - 1)\n",
    "    feature_dict[\"pfcand_etarel\"] = eta_sign * (jet_pfcands.eta - jet.eta)\n",
    "    feature_dict[\"pfcand_phirel\"] = jet.delta_phi(jet_pfcands)\n",
    "    feature_dict[\"pfcand_abseta\"] = np.abs(jet_pfcands.eta)\n",
    "\n",
    "    feature_dict[\"pfcand_pt_log_nopuppi\"] = np.log(jet_pfcands.pt)\n",
    "    feature_dict[\"pfcand_e_log_nopuppi\"] = np.log(jet_pfcands.energy)\n",
    "\n",
    "    pdgIds = jet_pfcands.pdgId\n",
    "    feature_dict[\"pfcand_isEl\"] = np.abs(pdgIds) == 11\n",
    "    feature_dict[\"pfcand_isMu\"] = np.abs(pdgIds) == 13\n",
    "    feature_dict[\"pfcand_isChargedHad\"] = np.abs(pdgIds) == 211\n",
    "    feature_dict[\"pfcand_isGamma\"] = np.abs(pdgIds) == 22\n",
    "    feature_dict[\"pfcand_isNeutralHad\"] = np.abs(pdgIds) == 130\n",
    "\n",
    "    feature_dict[\"pfcand_charge\"] = jet_pfcands.charge\n",
    "    feature_dict[\"pfcand_VTX_ass\"] = jet_pfcands.pvAssocQuality\n",
    "    feature_dict[\"pfcand_lostInnerHits\"] = jet_pfcands.lostInnerHits\n",
    "    feature_dict[\"pfcand_quality\"] = jet_pfcands.trkQuality\n",
    "\n",
    "    feature_dict[\"pfcand_normchi2\"] = np.floor(jet_pfcands.trkChi2)\n",
    "\n",
    "    if \"Cdz\" in jet_ak_pfcands.fields:\n",
    "        feature_dict[\"pfcand_dz\"] = jet_ak_pfcands[\"Cdz\"][pfcand_sort]\n",
    "        feature_dict[\"pfcand_dxy\"] = jet_ak_pfcands[\"Cdxy\"][pfcand_sort]\n",
    "        feature_dict[\"pfcand_dzsig\"] = jet_ak_pfcands[\"Cdzsig\"][pfcand_sort]\n",
    "        feature_dict[\"pfcand_dxysig\"] = jet_ak_pfcands[\"Cdxysig\"][pfcand_sort]\n",
    "    else:\n",
    "        # this is for old PFNano (<= v2.3)\n",
    "        feature_dict[\"pfcand_dz\"] = jet_pfcands.dz\n",
    "        feature_dict[\"pfcand_dxy\"] = jet_pfcands.d0\n",
    "        feature_dict[\"pfcand_dzsig\"] = jet_pfcands.dz / jet_pfcands.dzErr\n",
    "        feature_dict[\"pfcand_dxysig\"] = jet_pfcands.d0 / jet_pfcands.d0Err\n",
    "\n",
    "    feature_dict[\"pfcand_px\"] = jet_pfcands.px\n",
    "    feature_dict[\"pfcand_py\"] = jet_pfcands.py\n",
    "    feature_dict[\"pfcand_pz\"] = jet_pfcands.pz\n",
    "    feature_dict[\"pfcand_energy\"] = jet_pfcands.E\n",
    "    # feature_dict[\"pfcand_energy\"] = jet_pfcands.energy\n",
    "\n",
    "    # btag vars\n",
    "    for var in tagger_vars[\"pf_features\"][\"var_names\"]:\n",
    "        if \"btag\" in var:\n",
    "            feature_dict[var] = jet_ak_pfcands[var[len(\"pfcand_\") :]][pfcand_sort]\n",
    "\n",
    "    # pfcand mask\n",
    "    feature_dict[\"pfcand_mask\"] = (\n",
    "        ~(\n",
    "            ma.masked_invalid(\n",
    "                ak.pad_none(\n",
    "                    feature_dict[\"pfcand_abseta\"],\n",
    "                    tagger_vars[\"pf_features\"][\"var_length\"],\n",
    "                    axis=1,\n",
    "                    clip=True,\n",
    "                ).to_numpy()\n",
    "            ).mask\n",
    "        )\n",
    "    ).astype(np.float32)\n",
    "\n",
    "    # if no padding is needed, mask will = 1.0\n",
    "    if isinstance(feature_dict[\"pfcand_mask\"], np.float32):\n",
    "        feature_dict[\"pfcand_mask\"] = np.ones(\n",
    "            (\n",
    "                len(feature_dict[\"pfcand_abseta\"]),\n",
    "                tagger_vars[\"pf_features\"][\"var_length\"],\n",
    "            )\n",
    "        ).astype(np.float32)\n",
    "\n",
    "    repl_values_dict = {\n",
    "        \"pfcand_normchi2\": [-1, 999],\n",
    "        \"pfcand_dz\": [-1, 0],\n",
    "        \"pfcand_dzsig\": [1, 0],\n",
    "        \"pfcand_dxy\": [-1, 0],\n",
    "        \"pfcand_dxysig\": [1, 0],\n",
    "    }\n",
    "\n",
    "    # convert to numpy arrays and normalize features\n",
    "    if \"pf_vectors\" in tagger_vars.keys():\n",
    "        variables = set(tagger_vars[\"pf_features\"][\"var_names\"] + tagger_vars[\"pf_vectors\"][\"var_names\"])\n",
    "    else:\n",
    "        variables = tagger_vars[\"pf_features\"][\"var_names\"]\n",
    "\n",
    "    for var in variables:\n",
    "        a = (\n",
    "            ak.pad_none(\n",
    "                feature_dict[var],\n",
    "                tagger_vars[\"pf_features\"][\"var_length\"],\n",
    "                axis=1,\n",
    "                clip=True,\n",
    "            )\n",
    "            .to_numpy()\n",
    "            .filled(fill_value=0)\n",
    "        ).astype(np.float32)\n",
    "        a = np.nan_to_num(a)\n",
    "\n",
    "        # replace values to match PKU's\n",
    "        if var in repl_values_dict:\n",
    "            vals = repl_values_dict[var]\n",
    "            a[a == vals[0]] = vals[1]\n",
    "\n",
    "        if normalize:\n",
    "            if var in tagger_vars[\"pf_features\"][\"var_names\"]:\n",
    "                info = tagger_vars[\"pf_features\"][\"var_infos\"][var]\n",
    "            else:\n",
    "                info = tagger_vars[\"pf_vectors\"][\"var_infos\"][var]\n",
    "\n",
    "            a = (a - info[\"median\"]) * info[\"norm_factor\"]\n",
    "            a = np.clip(a, info.get(\"lower_bound\", -5), info.get(\"upper_bound\", 5))\n",
    "\n",
    "        feature_dict[var] = a\n",
    "\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from coffea.nanoevents.methods.nanoaod import FatJetArray, GenParticleArray\n",
    "\n",
    "def get_pid_mask(\n",
    "    genparts: GenParticleArray,\n",
    "    pdgids: Union[int, list],\n",
    "    ax: int = 2,\n",
    "    byall: bool = True,\n",
    ") -> ak.Array:\n",
    "    \"\"\"\n",
    "    Get selection mask for gen particles matching any of the pdgIds in ``pdgids``.\n",
    "    If ``byall``, checks all particles along axis ``ax`` match.\n",
    "    \"\"\"\n",
    "    gen_pdgids = abs(genparts.pdgId)\n",
    "\n",
    "    if type(pdgids) == list:\n",
    "        mask = gen_pdgids == pdgids[0]\n",
    "        for pdgid in pdgids[1:]:\n",
    "            mask = mask | (gen_pdgids == pdgid)\n",
    "    else:\n",
    "        mask = gen_pdgids == pdgids\n",
    "\n",
    "    return ak.all(mask, axis=ax) if byall else mask\n",
    "\n",
    "d_PDGID = 1\n",
    "c_PDGID = 4\n",
    "b_PDGID = 5\n",
    "g_PDGID = 21\n",
    "TOP_PDGID = 6\n",
    "\n",
    "ELE_PDGID = 11\n",
    "vELE_PDGID = 12\n",
    "MU_PDGID = 13\n",
    "vMU_PDGID = 14\n",
    "TAU_PDGID = 15\n",
    "vTAU_PDGID = 16\n",
    "\n",
    "Z_PDGID = 23\n",
    "W_PDGID = 24\n",
    "HIGGS_PDGID = 25\n",
    "\n",
    "PI_PDGID = 211\n",
    "PO_PDGID = 221\n",
    "PP_PDGID = 111\n",
    "\n",
    "GEN_FLAGS = [\"fromHardProcess\", \"isLastCopy\"]\n",
    "\n",
    "FILL_NONE_VALUE = -99999\n",
    "\n",
    "JET_DR = 0.8\n",
    "\n",
    "def to_label(array: ak.Array) -> ak.Array:\n",
    "    return ak.values_astype(array, np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genparts = events.GenPart\n",
    "fatjet = candidatefj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dau_pdgid=W_PDGID\n",
    "\n",
    "\"\"\"Gen matching for Higgs samples\"\"\"\n",
    "higgs = genparts[get_pid_mask(genparts, HIGGS_PDGID, byall=False) * genparts.hasFlags(GEN_FLAGS)]\n",
    "\n",
    "# only select events that match a specific decay\n",
    "signal_mask = ak.firsts(ak.all(abs(higgs.children.pdgId) == dau_pdgid, axis=2))\n",
    "\n",
    "matched_higgs = higgs[ak.argmin(fatjet.delta_r(higgs), axis=1, keepdims=True)][:, 0]\n",
    "matched_higgs_children = matched_higgs.children\n",
    "\n",
    "genVars = {\"fj_genH_pt\": ak.fill_none(matched_higgs.pt, FILL_NONE_VALUE)}\n",
    "\n",
    "if dau_pdgid == W_PDGID:\n",
    "    children_mask = get_pid_mask(matched_higgs_children, [W_PDGID], byall=False)\n",
    "    matched_higgs_children = matched_higgs_children[children_mask]\n",
    "\n",
    "    # order by mass, select lower mass child as V* and higher as V\n",
    "    children_mass = matched_higgs_children.mass\n",
    "    v_star = ak.firsts(matched_higgs_children[ak.argmin(children_mass, axis=1, keepdims=True)])\n",
    "    v = ak.firsts(matched_higgs_children[ak.argmax(children_mass, axis=1, keepdims=True)])\n",
    "\n",
    "    is_hww_matched = ak.any(children_mask, axis=1)\n",
    "\n",
    "    genVVars = {\n",
    "        \"fj_genV_dR\": fatjet.delta_r(v),\n",
    "        \"fj_genVstar\": fatjet.delta_r(v_star),\n",
    "        \"genV_genVstar_dR\": v.delta_r(v_star),\n",
    "    }\n",
    "\n",
    "    # VV daughters\n",
    "    daughters = ak.flatten(matched_higgs_children.distinctChildren, axis=2)\n",
    "    daughters = daughters[daughters.hasFlags(GEN_FLAGS)]\n",
    "    daughters_pdgId = abs(daughters.pdgId)\n",
    "\n",
    "    # exclude neutrinos from nprongs count\n",
    "    daughters_nov = daughters[\n",
    "        ((daughters_pdgId != vELE_PDGID) & (daughters_pdgId != vMU_PDGID) & (daughters_pdgId != vTAU_PDGID))\n",
    "    ]\n",
    "    nprongs = ak.sum(fatjet.delta_r(daughters_nov) < JET_DR, axis=1)\n",
    "\n",
    "    # get tau decays\n",
    "    taudaughters = daughters[(daughters_pdgId == TAU_PDGID)].children\n",
    "    taudaughters = taudaughters[taudaughters.hasFlags([\"isLastCopy\"])]\n",
    "    taudaughters_pdgId = abs(taudaughters.pdgId)\n",
    "\n",
    "    taudecay = (\n",
    "        # pions/kaons (hadronic tau) * 1\n",
    "        (\n",
    "            ak.sum(\n",
    "                (taudaughters_pdgId == ELE_PDGID) | (taudaughters_pdgId == MU_PDGID),\n",
    "                axis=1,\n",
    "            )\n",
    "            == 0\n",
    "        )\n",
    "        * 1\n",
    "        # 1 electron * 3\n",
    "        + (ak.sum(taudaughters_pdgId == ELE_PDGID, axis=1) == 1) * 3\n",
    "        # 1 muon * 5\n",
    "        + (ak.sum(taudaughters_pdgId == MU_PDGID, axis=1) == 1) * 5\n",
    "    )\n",
    "    # flatten taudecay - so painful\n",
    "    taudecay = ak.sum(taudecay, axis=-1)\n",
    "\n",
    "    # lepton daughters\n",
    "    lepdaughters = daughters[\n",
    "        ((daughters_pdgId == ELE_PDGID) | (daughters_pdgId == MU_PDGID) | (daughters_pdgId == TAU_PDGID))\n",
    "    ]\n",
    "    lepinprongs = ak.sum(fatjet.delta_r(lepdaughters) < JET_DR, axis=1)  # should be 0 or 1\n",
    "\n",
    "    lepton_parent = ak.firsts(lepdaughters[fatjet.delta_r(lepdaughters) < JET_DR].distinctParent)\n",
    "    lepton_parent_mass = lepton_parent.mass\n",
    "\n",
    "    iswlepton = lepton_parent_mass == v.mass\n",
    "    iswstarlepton = lepton_parent_mass == v_star.mass    \n",
    "    \n",
    "    decay = (\n",
    "        # 2 quarks * 1\n",
    "        (ak.sum(daughters_pdgId <= b_PDGID, axis=1) == 2) * 1\n",
    "        # 1 electron * 3\n",
    "        + (ak.sum(daughters_pdgId == ELE_PDGID, axis=1) == 1) * 3\n",
    "        # 1 muon * 5\n",
    "        + (ak.sum(daughters_pdgId == MU_PDGID, axis=1) == 1) * 5\n",
    "        # 1 tau * 7\n",
    "        + (ak.sum(daughters_pdgId == TAU_PDGID, axis=1) == 1) * 7\n",
    "        # 4 quarks * 11\n",
    "        + (ak.sum(daughters_pdgId <= b_PDGID, axis=1) == 4) * 11\n",
    "    )\n",
    "\n",
    "    # number of c quarks in V decay inside jet\n",
    "    cquarks = daughters_nov[abs(daughters_nov.pdgId) == c_PDGID]\n",
    "    ncquarks = ak.sum(fatjet.delta_r(cquarks) < JET_DR, axis=1)\n",
    "\n",
    "    genHVVVars = {\n",
    "        \"fj_nprongs\": nprongs,\n",
    "        \"fj_ncquarks\": ncquarks,\n",
    "        \"fj_lepinprongs\": lepinprongs,\n",
    "        \"fj_H_VV_4q\": to_label(decay == 11),\n",
    "        \"fj_H_VV_elenuqq\": to_label(decay == 4),\n",
    "        \"fj_H_VV_munuqq\": to_label(decay == 6),\n",
    "        \"fj_H_VV_leptauelvqq\": to_label((decay == 8) & (taudecay == 3)),\n",
    "        \"fj_H_VV_leptaumuvqq\": to_label((decay == 8) & (taudecay == 5)),\n",
    "        \"fj_H_VV_hadtauvqq\": to_label((decay == 8) & (taudecay == 1)),\n",
    "        \"fj_H_VV_isVlepton\": iswlepton,\n",
    "        \"fj_H_VV_isVstarlepton\": iswstarlepton,\n",
    "        \"fj_H_VV_isMatched\": is_hww_matched,\n",
    "    }\n",
    "\n",
    "    genVars = {**genVars, **genVVars, **genHVVVars}\n",
    "\n",
    "elif dau_pdgid == TAU_PDGID:\n",
    "    children_mask = get_pid_mask(matched_higgs_children, [TAU_PDGID], byall=False)\n",
    "    daughters = matched_higgs_children[children_mask]\n",
    "\n",
    "    is_htt_matched = ak.any(children_mask, axis=1)\n",
    "\n",
    "    taudaughters = daughters[(abs(daughters.pdgId) == TAU_PDGID)].children\n",
    "    taudaughters = taudaughters[taudaughters.hasFlags([\"isLastCopy\"])]\n",
    "    taudaughters_pdgId = abs(taudaughters.pdgId)\n",
    "\n",
    "    taudaughters = taudaughters[\n",
    "        ((taudaughters_pdgId != vELE_PDGID) & (taudaughters_pdgId != vMU_PDGID) & (taudaughters_pdgId != vTAU_PDGID))\n",
    "    ]\n",
    "    taudaughters_pdgId = abs(taudaughters.pdgId)\n",
    "\n",
    "    flat_taudaughters_pdgId = ak.flatten(taudaughters_pdgId, axis=2)\n",
    "\n",
    "    extra_taus = ak.any(taudaughters_pdgId == TAU_PDGID, axis=2)\n",
    "    children_pdgId = abs(taudaughters[extra_taus].children.pdgId)\n",
    "\n",
    "    taudecay = (\n",
    "        # pions/kaons (full hadronic tau) * 1\n",
    "        (\n",
    "            (\n",
    "                ak.sum(\n",
    "                    (flat_taudaughters_pdgId == PI_PDGID)\n",
    "                    | (flat_taudaughters_pdgId == PO_PDGID)\n",
    "                    | (flat_taudaughters_pdgId == PP_PDGID),\n",
    "                    axis=1,\n",
    "                )\n",
    "                > 0\n",
    "            )\n",
    "        )\n",
    "        * 1\n",
    "        # 1 electron * 3\n",
    "        + (ak.sum(flat_taudaughters_pdgId == ELE_PDGID, axis=1) == 1) * 3\n",
    "        # 1 muon * 5\n",
    "        + (ak.sum(flat_taudaughters_pdgId == MU_PDGID, axis=1) == 1) * 5\n",
    "        # two leptons\n",
    "        + (\n",
    "            (ak.sum(flat_taudaughters_pdgId == ELE_PDGID, axis=1) == 2)\n",
    "            | (ak.sum(flat_taudaughters_pdgId == MU_PDGID, axis=1) == 2)\n",
    "        )\n",
    "        * 7\n",
    "    )\n",
    "\n",
    "    extradecay = (\n",
    "        (\n",
    "            (\n",
    "                ak.sum(\n",
    "                    ak.sum(\n",
    "                        (children_pdgId == PI_PDGID) | (children_pdgId == PO_PDGID) | (children_pdgId == PP_PDGID),\n",
    "                        axis=-1,\n",
    "                    ),\n",
    "                    axis=1,\n",
    "                )\n",
    "                > 0\n",
    "            )\n",
    "        )\n",
    "        * 1\n",
    "        + (ak.sum(ak.sum(children_pdgId == ELE_PDGID, axis=-1), axis=1) == 1) * 3\n",
    "        + (ak.sum(ak.sum(children_pdgId == MU_PDGID, axis=-1), axis=1) == 1) * 5\n",
    "        + (\n",
    "            (ak.sum(ak.sum(children_pdgId == MU_PDGID, axis=-1), axis=1) == 2)\n",
    "            | (ak.sum(ak.sum(children_pdgId == ELE_PDGID, axis=-1), axis=1) == 2)\n",
    "        )\n",
    "        * 7\n",
    "    )\n",
    "    extradecay = ak.sum(extradecay, axis=-1)\n",
    "\n",
    "    elehad = ((taudecay == 4) & (extradecay == 0)) | ((extradecay == 4) & (taudecay == 0))\n",
    "    muhad = ((taudecay == 6) & (extradecay == 0)) | ((extradecay == 6) & (taudecay == 0))\n",
    "    leplep = ((taudecay == 7) | (taudecay == 8)) | ((extradecay == 7) | (extradecay == 8))\n",
    "    hadhad = ~elehad & ~muhad & ~leplep\n",
    "\n",
    "    # to painfully debug\n",
    "    # np.set_printoptions(threshold=np.inf)\n",
    "    # print(ak.argsort((is_htt_matched)).to_numpy())\n",
    "    # print(ak.flatten(taudecay).to_numpy())\n",
    "    # idx= ak.argsort((is_htt_matched)).to_numpy()\n",
    "    # idx = [74,2023,2037,2887,3121,3435,3838,4599,4702,4906,5266,5703,6063,6498,6799,7642,8820,8828,8999,9005,9455,9564,\n",
    "    # 11178,11597,11736,12207,12325,12504,12697,12780,13151,13690]\n",
    "    # for i in idx:\n",
    "    #     print(i,flat_taudaughters_pdgId[i],extra_taus[i],children_pdgId[i])\n",
    "    #     print(elehad[i],muhad[i],leplep[i],hadhad[i])\n",
    "    #     print(taudecay[i],extradecay[i])\n",
    "\n",
    "    genHTTVars = {\n",
    "        \"fj_H_tt_hadhad\": to_label(hadhad),\n",
    "        \"fj_H_tt_elehad\": to_label(elehad),\n",
    "        \"fj_H_tt_muhad\": to_label(muhad),\n",
    "        \"fj_H_tt_leplep\": to_label(leplep),\n",
    "        \"fj_H_tt_isMatched\": is_htt_matched,\n",
    "    }\n",
    "\n",
    "    genVars = {**genVars, **genHTTVars}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fj_genH_pt': <Array [-1e+05, -1e+05, ... -1e+05, -1e+05] type='98400 * float64'>,\n",
       " 'fj_genV_dR': <Array [None, None, None, ... None, None, None] type='98400 * ?float32'>,\n",
       " 'fj_genVstar': <Array [None, None, None, ... None, None, None] type='98400 * ?float32'>,\n",
       " 'genV_genVstar_dR': <Array [None, None, None, ... None, None, None] type='98400 * ?float32'>,\n",
       " 'fj_nprongs': <Array [None, None, None, ... None, None, None] type='98400 * ?int64'>,\n",
       " 'fj_ncquarks': <Array [None, None, None, ... None, None, None] type='98400 * ?int64'>,\n",
       " 'fj_lepinprongs': <Array [None, None, None, ... None, None, None] type='98400 * ?int64'>,\n",
       " 'fj_H_VV_4q': <Array [None, None, None, ... None, None, None] type='98400 * ?int32'>,\n",
       " 'fj_H_VV_elenuqq': <Array [None, None, None, ... None, None, None] type='98400 * ?int32'>,\n",
       " 'fj_H_VV_munuqq': <Array [None, None, None, ... None, None, None] type='98400 * ?int32'>,\n",
       " 'fj_H_VV_leptauelvqq': <Array [None, None, None, ... None, None, None] type='98400 * ?int32'>,\n",
       " 'fj_H_VV_leptaumuvqq': <Array [None, None, None, ... None, None, None] type='98400 * ?int32'>,\n",
       " 'fj_H_VV_hadtauvqq': <Array [None, None, None, ... None, None, None] type='98400 * ?int32'>,\n",
       " 'fj_H_VV_isVlepton': <Array [None, None, None, ... None, None, None] type='98400 * ?bool'>,\n",
       " 'fj_H_VV_isVstarlepton': <Array [None, None, None, ... None, None, None] type='98400 * ?bool'>,\n",
       " 'fj_H_VV_isMatched': <Array [None, None, None, ... None, None, None] type='98400 * ?bool'>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genVars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
