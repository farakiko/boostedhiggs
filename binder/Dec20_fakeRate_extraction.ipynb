{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making stacked histograms\n",
    "- processes an `events[year][ch][sample]` object using `make_events_dict()`\n",
    "- uses `plot_hists()` to make stacked histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import yaml\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "from scipy.special import softmax\n",
    "\n",
    "import hist as hist2\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "\n",
    "import sys\n",
    "sys.path\n",
    "sys.path.append(\"../python/\")\n",
    "\n",
    "import utils\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ele': {'Run2': 137640.0,\n",
       "  '2016APV': 19492.72,\n",
       "  '2016': 16809.96,\n",
       "  '2017': 41476.02,\n",
       "  '2018': 59816.23},\n",
       " 'mu': {'Run2': 137640.0,\n",
       "  '2016APV': 19436.16,\n",
       "  '2016': 16810.81,\n",
       "  '2017': 41475.26,\n",
       "  '2018': 59781.96},\n",
       " 'lep': {'Run2': 137640.0,\n",
       "  '2016APV': 19436.16,\n",
       "  '2016': 16810.81,\n",
       "  '2017': 41475.26,\n",
       "  '2018': 59781.96},\n",
       " 'had': {'Run2': 137640.0,\n",
       "  '2016APV': 19436.16,\n",
       "  '2016': 16810.81,\n",
       "  '2017': 41475.26,\n",
       "  '2018': 59781.96}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get lumi\n",
    "with open(\"../fileset/luminosity.json\") as f:\n",
    "    luminosity = json.load(f)\n",
    "    \n",
    "luminosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lumi(years, channels):\n",
    "    lum_ = 0\n",
    "    for year in years:\n",
    "        lum = 0\n",
    "        for ch in channels:\n",
    "            lum += luminosity[ch][year] / 1000.0\n",
    "\n",
    "        lum_ += lum / len(channels)    \n",
    "    return lum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " # define your regions here\n",
    "presel = {\n",
    "        \"mu\": {\n",
    "            \"met\": \"met_pt<20\",\n",
    "#             \"met\": \"met_pt>10\",\n",
    "#             \"fj_mass\": \"fj_mass>10\",\n",
    "            \"miso\": \" (loose_lep1_pt<55) | ( (loose_lep1_pt>55) & (loose_lep1_miso<0.8) ) \"            \n",
    "        },\n",
    "        \"ele\": {\n",
    "            \"met\": \"met_pt<20\",\n",
    "#             \"met\": \"met_pt>10\",\n",
    "#             \"fj_mass\": \"fj_mass>10\",\n",
    "        },\n",
    "}\n",
    "\n",
    "\n",
    "channels = [\"ele\", \"mu\"]\n",
    "samples = [\n",
    "    \"QCD\",\n",
    "    \"Data\",\n",
    "    \"DYJets\",\n",
    "    \"WJetsLNu\",\n",
    "]\n",
    "\n",
    "years = [\"2016\", \"2016APV\", \"2017\", \"2018\"]\n",
    "# years = [\"2017\"]\n",
    "\n",
    "samples_dir = {\n",
    "    \"ele\": {\n",
    "        \"2018\": \"../eos/fake_rate_extraction/May31_fakes_2018\",\n",
    "        \"2017\": \"../eos/fake_rate_extraction/May31_fakes_2017\",\n",
    "        \"2016\": \"../eos/fake_rate_extraction/May31_fakes_2016\",\n",
    "        \"2016APV\": \"../eos/fake_rate_extraction/May31_fakes_2016APV\",\n",
    "    },\n",
    "    \n",
    "    \"mu\": {\n",
    "        \"2018\": \"../eos/fake_rate_extraction/Oct9_fakes_mu_2018\",\n",
    "        \"2017\": \"../eos/fake_rate_extraction/Oct9_fakes_mu_2017\",\n",
    "        \"2016\": \"../eos/fake_rate_extraction/Oct9_fakes_mu_2016\",\n",
    "        \"2016APV\": \"../eos/fake_rate_extraction/Oct9_fakes_mu_2016APV\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Processing 2016, ele channel\n",
      "INFO:root:Processing 2016APV, ele channel\n",
      "INFO:root:Processing 2017, ele channel\n",
      "INFO:root:Processing 2018, ele channel\n",
      "INFO:root:Processing 2016, mu channel\n",
      "INFO:root:Processing 2016APV, mu channel\n",
      "INFO:root:Processing 2017, mu channel\n",
      "INFO:root:Processing 2018, mu channel\n"
     ]
    }
   ],
   "source": [
    "from make_stacked_hists import make_events_dict\n",
    "\n",
    "channels = [\n",
    "    \"ele\",\n",
    "    \"mu\",\n",
    "]\n",
    "\n",
    "out = {}\n",
    "for ch in channels:\n",
    "    out[ch] = make_events_dict(years, [ch], samples_dir[ch], samples, presel)\n",
    "\n",
    "# wrap\n",
    "events_dict = {}\n",
    "for year in years:\n",
    "    events_dict[year] = {}\n",
    "    for ch in channels:\n",
    "        events_dict[year][ch] = out[ch][year][ch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_neg_yields(h):\n",
    "    \"\"\"\n",
    "    Will set the bin yields of a process to 0 if the nominal yield is negative, and will\n",
    "    set the yield to 0 for the full Systematic axis.\n",
    "    \"\"\"\n",
    "    for sample in h.axes[\"samples\"]:\n",
    "        neg_bins = np.where(h[{\"samples\": sample}].values() < 0)[0]\n",
    "\n",
    "        if len(neg_bins) > 0:\n",
    "            print(f\"{sample}, has {len(neg_bins)} bins with negative yield.. will set them to 0\")\n",
    "\n",
    "            sample_index = np.argmax(np.array(h.axes[\"samples\"]) == sample)\n",
    "\n",
    "            for neg_bin in neg_bins:\n",
    "                h.view(flow=True)[sample_index, neg_bin + 1] = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_tight_lep\n",
      "N_loose_lep\n",
      "tight_lep1_pt\n",
      "tight_lep1_eta\n",
      "tight_lep2_pt\n",
      "tight_lep2_eta\n",
      "mll_tight\n",
      "loose_lep1_pt\n",
      "loose_lep1_eta\n",
      "loose_lep2_pt\n",
      "loose_lep2_eta\n",
      "mll_loose\n",
      "met_pt\n",
      "NumFatjets\n",
      "lep_fj_dr\n",
      "fj_pt\n",
      "fj_eta\n",
      "fj_phi\n",
      "mT_tight1\n",
      "mT_loose1\n",
      "xsecweight\n",
      "nominal\n"
     ]
    }
   ],
   "source": [
    "for key in events_dict[\"2017\"][\"ele\"][\"Data\"].keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_plot = [\n",
    "#     \"N_tight_lep\",\n",
    "#     \"N_loose_lep\",\n",
    "    \"tight_lep1_pt\",\n",
    "#     \"tight_lep1_eta\",\n",
    "#     \"tight_lep2_pt\",\n",
    "#     \"tight_lep2_eta\",\n",
    "#     \"mll_tight\",\n",
    "    \"loose_lep1_pt\",\n",
    "#     \"loose_lep1_eta\",\n",
    "#     \"loose_lep2_pt\",\n",
    "#     \"loose_lep2_eta\",\n",
    "#     \"mll_loose\",\n",
    "#     \"met_pt\",\n",
    "#     \"mT_loose1\",\n",
    "#     \"mT_tight1\",\n",
    "]\n",
    "\n",
    "samples_to_plot = [\n",
    "    \"QCD\",\n",
    "    \"Data\",\n",
    "    \"DYJets\",\n",
    "    \"WJetsLNu\",    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'WJetsLNu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples_to_plot:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m years:\n\u001b[0;32m---> 74\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mevents_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43myear\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbarrel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m cut:\n\u001b[1;32m     77\u001b[0m             df \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;28mabs\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloose_lep1_eta\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1.48\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'WJetsLNu'"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "axis_dict = {}\n",
    "axis_dict[\"ele\"] = {\n",
    "    \"loose_lep1_pt\": hist2.axis.Regular(25, 38, 400, name=\"var\", label=r\"Loose electron $p_T$ [GeV]\", overflow=True),    \n",
    "    \"loose_lep1_eta\": hist2.axis.Regular(20, 0, 2.4, name=\"var\", label=r\"Loose electron |$\\eta$|\", overflow=True),    \n",
    "\n",
    "    \"tight_lep1_pt\": hist2.axis.Regular(25, 38, 200, name=\"var\", label=r\"Tight electron $p_T$ [GeV]\", overflow=True), \n",
    "    \"tight_lep1_eta\": hist2.axis.Regular(20, 0, 2.4, name=\"var\", label=r\"Tight electron |$\\eta$|\", overflow=True),\n",
    "\n",
    "    \"met_pt\": hist2.axis.Regular(40, 0, 20, name=\"var\", label=r\"MET [GeV]\", overflow=True),\n",
    "\n",
    "    \"loose_lep1_eta_endcaps\": hist2.axis.Regular(15, 1.57, 2.4, name=\"var\", label=r\"Loose electron |$\\eta$|\", overflow=True),\n",
    "    \"tight_lep1_eta_endcaps\": hist2.axis.Regular(15, 1.57, 2.4, name=\"var\", label=r\"Tight electron |$\\eta$|\", overflow=True),\n",
    "\n",
    "    \"loose_lep1_eta_barrel\": hist2.axis.Regular(20, 0, 1.57, name=\"var\", label=r\"Loose electron |$\\eta$|\", overflow=True),\n",
    "    \"tight_lep1_eta_barrel\": hist2.axis.Regular(20, 0, 1.57, name=\"var\", label=r\"Tight electron |$\\eta$|\", overflow=True),\n",
    "}\n",
    "\n",
    "axis_dict[\"mu\"] = {\n",
    "    \"loose_lep1_pt\": hist2.axis.Regular(15, 30, 300, name=\"var\", label=r\"Loose muon $p_T$ [GeV]\", overflow=True),    \n",
    "    \"loose_lep1_eta\": hist2.axis.Regular(20, 0, 2.4, name=\"var\", label=r\"Loose muon |$\\eta$|\", overflow=True),    \n",
    "\n",
    "    \"tight_lep1_pt\": hist2.axis.Regular(25, 30, 200, name=\"var\", label=r\"Tight muon $p_T$ [GeV]\", overflow=True), \n",
    "    \"tight_lep1_eta\": hist2.axis.Regular(20, 0, 2.4, name=\"var\", label=r\"Tight muon |$\\eta$|\", overflow=True),\n",
    "\n",
    "    \"met_pt\": hist2.axis.Regular(40, 0, 20, name=\"var\", label=r\"MET [GeV]\", overflow=True),\n",
    "    \n",
    "    \"loose_lep1_eta_endcaps\": hist2.axis.Regular(15, 1.479, 2.4, name=\"var\", label=r\"Loose muon |$\\eta$|\", overflow=True),\n",
    "    \"tight_lep1_eta_endcaps\": hist2.axis.Regular(15, 1.479, 2.4, name=\"var\", label=r\"Tight muon |$\\eta$|\", overflow=True),\n",
    "\n",
    "    \"loose_lep1_eta_barrel\": hist2.axis.Regular(20, 0, 1.479, name=\"var\", label=r\"Loose muon |$\\eta$|\", overflow=True),\n",
    "    \"tight_lep1_eta_barrel\": hist2.axis.Regular(20, 0, 1.479, name=\"var\", label=r\"Tight muon |$\\eta$|\", overflow=True),        \n",
    "}\n",
    "\n",
    "years = [\n",
    "    \"2016\", \n",
    "    \"2016APV\", \n",
    "    \"2017\",\n",
    "    \"2018\",\n",
    "]\n",
    "\n",
    "channels = [\n",
    "    \"ele\",\n",
    "    \"mu\",\n",
    "]\n",
    "\n",
    "# cut = \"endcaps\"\n",
    "cut = \"barrel\"\n",
    "# cut = \"\"\n",
    "\n",
    "# fill histograms\n",
    "hists = {}\n",
    "\n",
    "for ch in channels:\n",
    "    for var in vars_to_plot:\n",
    "\n",
    "        if (\"barrel\" in cut) and (\"eta\" in var):\n",
    "            ax = axis_dict[ch][var + \"_barrel\"]\n",
    "        elif (\"endcaps\" in cut) and (\"eta\" in var):\n",
    "            ax = axis_dict[ch][var + \"_endcaps\"]\n",
    "        else:\n",
    "            ax = axis_dict[ch][var]\n",
    "            \n",
    "        hists[var] = hist2.Hist(\n",
    "            hist2.axis.StrCategory([], name=\"samples\", growth=True),\n",
    "            ax,\n",
    "            storage=hist2.storage.Weight(),            \n",
    "        )\n",
    "\n",
    "        for sample in samples_to_plot:\n",
    "            for year in years:\n",
    "\n",
    "                df = events_dict[year][ch][sample]\n",
    "\n",
    "                if \"barrel\" in cut:\n",
    "                    df = df[abs(df[\"loose_lep1_eta\"]) < 1.48]\n",
    "                elif \"endcaps\" in cut:\n",
    "                    df = df[abs(df[\"loose_lep1_eta\"]) > 1.48]\n",
    "\n",
    "                # get the absolute of eta in case that is the variable to be plotted\n",
    "                if \"eta\" in var:\n",
    "                    x = abs(df[var])\n",
    "                else:\n",
    "                    x = df[var]\n",
    "                \n",
    "                w = df[\"nominal\"]\n",
    "\n",
    "#                 msk = (w<100) & (w>-100)\n",
    "#                 x = x[msk]\n",
    "#                 w = w[msk]\n",
    "\n",
    "                hists[var].fill(\n",
    "                    samples=sample,\n",
    "                    var=x,\n",
    "                    weight=w,\n",
    "                )  \n",
    "\n",
    "    for var in vars_to_plot:\n",
    "        fix_neg_yields(hists[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nice_ch = {\n",
    "    \"ele\": \"Electron channel\",\n",
    "    \"mu\": \"Muon channel\",\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 20})\n",
    "add_data = True\n",
    "add_soverb = False\n",
    "    \n",
    "from utils import plot_hists as plot_hists\n",
    "\n",
    "if len(years)>1:\n",
    "    PATH = f\"/Users/fmokhtar/Desktop/AN_2024/fakes/{ch}_Run2\"\n",
    "else:\n",
    "    PATH = f\"/Users/fmokhtar/Desktop/AN_2024/fakes/{ch}_{year}\"\n",
    "\n",
    "PATH = f\"/Users/fmokhtar/Desktop/AN_2024/ARC/fakes/\"\n",
    "\n",
    "if not os.path.exists(PATH):\n",
    "    # Create the directory\n",
    "    os.makedirs(PATH)    \n",
    "\n",
    "if \"barrel\" in cut:\n",
    "    add_text = \" (barrel)\"\n",
    "elif \"endcaps\" in cut:\n",
    "    add_text = \" (endcaps)\"\n",
    "else:\n",
    "    add_text = \"\"\n",
    "    \n",
    "plot_hists(hists, years, channels, vars_to_plot,\n",
    "            add_data=True,\n",
    "            logy=False,\n",
    "            mult=1,\n",
    "            outpath=PATH,\n",
    "            text_=nice_ch[ch] + add_text,\n",
    "            blind_region=False,\n",
    "            save_as=cut,\n",
    "            plot_Fake_unc=0.5,\n",
    "#             plot_syst_unc=(SYST_UNC_up, SYST_UNC_down) if plot_syst_unc else None,\n",
    "#            add_soverb=True,\n",
    "           legend_ncol=2,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"/Users/fmokhtar/Desktop/AN_2024/ARC/fakes/\"\n",
    "\n",
    "lab_var_dict = {\n",
    "    \"FR_Nominal\": \"nominal\",\n",
    "    \"FR_stat\": \"stat. unc.\",\n",
    "    \"EWK_SF\": \"EWK SF stat. unc.\",\n",
    "}\n",
    "\n",
    "def plot_matrix(FR, ch, variation, title=None):\n",
    "    \n",
    "    M = FR[variation]\n",
    "    \n",
    "    if ch == \"ele\":\n",
    "        fig, ax = plt.subplots(figsize=(18,23))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=(16,16))\n",
    "    \n",
    "    im = ax.imshow(M, vmax=1, vmin=0, cmap='coolwarm')\n",
    "    \n",
    "    # merge the first bin up 2000GeV\n",
    "    ptbinning[ch][0] = 2000\n",
    "    \n",
    "    ax.set_xticks(ticks=np.arange(-0.5, (len(etabinning)-1), 1), labels=np.round(etabinning,2))\n",
    "    ax.set_yticks(ticks=np.arange(-0.5, (len(ptbinning[ch])-1), 1), labels=np.round(ptbinning[ch],2))\n",
    "\n",
    "    ax.tick_params(axis='x', which='major', pad=8)\n",
    "    ax.tick_params(axis='y', which='major', pad=8)\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(len(ptbinning[ch])-1):\n",
    "        for j in range(len(etabinning)-1):\n",
    "            if variation == \"FR_Nominal\":\n",
    "                text = ax.text(j, i, str(np.round(M[i, j],3)), ha=\"center\", va=\"center\", fontsize=45)\n",
    "            else: # annotate +=\n",
    "                unc = abs(FR[\"FR_Nominal\"][i, j] - M[i, j])\n",
    "                text = ax.text(j, i, str(np.round(FR[\"FR_Nominal\"][i, j],3)) + r\" $\\pm$ \" + str(np.round(unc,3)), ha=\"center\", fontsize=45)\n",
    "\n",
    "    ax.set_xlabel(r\"$\\eta$\", fontsize=30)\n",
    "    ax.set_ylabel(r\"$p_T$\", fontsize=30)\n",
    "\n",
    "    cbar = plt.colorbar(im, shrink=0.6)\n",
    "    cbar.ax.tick_params(labelsize=30)\n",
    "    \n",
    "    # Improve axis ticks\n",
    "    ax.tick_params(axis='x', labelsize=30)\n",
    "    ax.tick_params(axis='y', labelsize=30)\n",
    "\n",
    "    hep.cms.lumitext(\"%.0f \" % get_lumi(years, channels) + r\"fb$^{-1}$ (13 TeV)\", ax=ax, fontsize=30)\n",
    "    hep.cms.text(\"Work in Progress\", ax=ax, fontsize=25);\n",
    "\n",
    "    if \"Nominal\" in variation:\n",
    "        title_ = r\"fake rate\"\n",
    "    else:\n",
    "        title_ = r\"fake rate ($\\pm$ \" + f\"{lab_var_dict[title]})\"\n",
    "    \n",
    "    if ch == \"ele\":\n",
    "        ax.set_title(\"Electron \" + title_, pad=50, fontsize=50)\n",
    "    else:\n",
    "        ax.set_title(\"Muon \" + title_, pad=50, fontsize=40)\n",
    "    plt.tight_layout()        \n",
    "    plt.savefig(f\"{PATH}/fakerates/{ch}_fake_{title}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake rate extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FR_Nominal ele (4, 2)\n",
      "FR_stat_Up ele (4, 2)\n",
      "FR_stat_Down ele (4, 2)\n",
      "EWK_SF_Up ele (4, 2)\n",
      "EWK_SF_Down ele (4, 2)\n",
      "FR_Nominal mu (3, 2)\n",
      "FR_stat_Up mu (3, 2)\n",
      "FR_stat_Down mu (3, 2)\n",
      "EWK_SF_Up mu (3, 2)\n",
      "EWK_SF_Down mu (3, 2)\n",
      "variation FR_Nominal, ele channel:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'WJetsLNu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 94\u001b[0m\n\u001b[1;32m     91\u001b[0m loose, tight \u001b[38;5;241m=\u001b[39m {}, {}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWJetsLNu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDYJets\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m---> 94\u001b[0m     pt \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloose_lep1_pt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     95\u001b[0m     eta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(df[sample][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloose_lep1_eta\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     97\u001b[0m     msk_pt \u001b[38;5;241m=\u001b[39m (pt \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m low_pt) \u001b[38;5;241m&\u001b[39m (pt \u001b[38;5;241m<\u001b[39m high_pt)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'WJetsLNu'"
     ]
    }
   ],
   "source": [
    "years = [\n",
    "    \"2018\",\n",
    "    \"2017\",\n",
    "    \"2016\",\n",
    "    \"2016APV\",\n",
    "]\n",
    "\n",
    "channels = [\n",
    "    \"ele\",\n",
    "    \"mu\",\n",
    "]\n",
    "\n",
    "ptbinning = {}\n",
    "ptbinning[\"ele\"] = [2000, 200, 160, 120, 30]\n",
    "ptbinning[\"mu\"] = [180, 80, 60, 30]\n",
    "\n",
    "etabinning = [0, 1.479, 2.5]\n",
    "\n",
    "SIGMA = {}\n",
    "for ch in channels:\n",
    "    SIGMA[ch] = np.zeros((len(ptbinning[ch])-1,len(etabinning)-1))\n",
    "\n",
    "variations = [\n",
    "    \"FR_Nominal\", \n",
    "    \"FR_stat_Up\", \n",
    "    \"FR_stat_Down\", \n",
    "    \"EWK_SF_Up\", \n",
    "    \"EWK_SF_Down\",\n",
    "]\n",
    "\n",
    "FR = {}\n",
    "\n",
    "for ch in channels:\n",
    "    FR[ch] = {}        \n",
    "\n",
    "    for variation in variations:\n",
    "\n",
    "        FR[ch][variation] = np.zeros((len(ptbinning[ch])-1,len(etabinning)-1))\n",
    "        print(variation, ch, FR[ch][variation].shape)\n",
    "        \n",
    "# get the SF\n",
    "EWK_SF = {\n",
    "    \"ele\":     {\n",
    "        \"Barrel_allpt\":         {\n",
    "            \"Nominal\": 0.796,\n",
    "            \"EWK_SF_Up\": 0.813,\n",
    "            \"EWK_SF_Down\": 0.780\n",
    "        },\n",
    "        \"Endcap_allpt\":         {\n",
    "            \"Nominal\": 0.838,\n",
    "            \"EWK_SF_Up\": 0.874,\n",
    "            \"EWK_SF_Down\": 0.801\n",
    "        },\n",
    "    },\n",
    "    \"mu\":     {\n",
    "        \"Barrel_allpt\":         {\n",
    "            \"Nominal\": 0.862,\n",
    "            \"EWK_SF_Up\": 0.876,\n",
    "            \"EWK_SF_Down\": 0.849\n",
    "        },\n",
    "        \"Endcap_allpt\":         {\n",
    "            \"Nominal\": 0.847,\n",
    "            \"EWK_SF_Up\": 0.870,\n",
    "            \"EWK_SF_Down\": 0.823\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "for variation in variations:\n",
    "    for ch in channels:\n",
    "\n",
    "        print(f\"variation {variation}, {ch} channel:\")   \n",
    "\n",
    "        for i in range(len(ptbinning[ch])-1):\n",
    "            high_pt, low_pt = ptbinning[ch][i], ptbinning[ch][i+1]\n",
    "            \n",
    "            for j in range(len(etabinning)-1):\n",
    "                low_eta, high_eta = etabinning[j], etabinning[j+1]\n",
    "                \n",
    "                if j == 0:\n",
    "                    ewksf = EWK_SF[ch][\"Barrel_allpt\"]\n",
    "                else:\n",
    "                    ewksf = EWK_SF[ch][\"Endcap_allpt\"]\n",
    "                \n",
    "                ############### loop over years START\n",
    "                num, den = 0, 0\n",
    "                for year in years:\n",
    "\n",
    "                    df = events_dict[year][ch]\n",
    "\n",
    "                    loose, tight = {}, {}\n",
    "                    for sample in [\"Data\", \"WJetsLNu\", \"DYJets\"]:\n",
    "                        \n",
    "                        pt = df[sample][\"loose_lep1_pt\"]\n",
    "                        eta = abs(df[sample][\"loose_lep1_eta\"])\n",
    "                        \n",
    "                        msk_pt = (pt >= low_pt) & (pt < high_pt)\n",
    "                        msk_eta = (eta >= low_eta) & (eta < high_eta)\n",
    "\n",
    "                        # get data tight/loose ratio\n",
    "                        msk_Nl1 = df[sample][\"N_loose_lep\"]==1                        \n",
    "                        msk_Nt1 = df[sample][\"N_tight_lep\"]==1\n",
    "\n",
    "                        loose[sample] = df[sample][\"nominal\"][msk_Nl1 & msk_pt & msk_eta].sum()                    \n",
    "                        tight[sample] = df[sample][\"nominal\"][msk_Nt1 & msk_pt & msk_eta].sum()\n",
    "\n",
    "                    if (variation==\"FR_Nominal\") or (variation==\"FR_stat_Up\") or (variation==\"FR_stat_Down\"):                \n",
    "                        ewk_corr = ewksf[\"Nominal\"]\n",
    "                    else:\n",
    "                        ewk_corr = ewksf[variation]\n",
    "\n",
    "                    num += ( tight[\"Data\"] - ewk_corr * (tight[\"WJetsLNu\"] + tight[\"DYJets\"]) )\n",
    "                    den += ( loose[\"Data\"] - ewk_corr * (loose[\"WJetsLNu\"] + loose[\"DYJets\"]) )\n",
    "\n",
    "                ############### loop over years END\n",
    "                \n",
    "                SIGMA[ch][i,j] = (num/den) * np.sqrt( (np.sqrt(num)/num)**2 + (np.sqrt(den)/den)**2 )                    \n",
    "\n",
    "                if (variation==\"FR_stat_Up\"):\n",
    "                    FR[ch][variation][i,j] = (num/den) + SIGMA[ch][i,j]\n",
    "                elif (variation==\"FR_stat_Down\"):\n",
    "                    FR[ch][variation][i,j] = (num/den) - SIGMA[ch][i,j]\n",
    "                else:\n",
    "                    FR[ch][variation][i,j] = (num/den)\n",
    "\n",
    "        print(\"----------------------------\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ch in channels:        \n",
    "    for variation in [\n",
    "        \"FR_Nominal\",\n",
    "        \"FR_stat_Up\",        \n",
    "        \"EWK_SF_Up\",\n",
    "    ]:\n",
    "        plot_matrix(FR[ch], ch, variation, title=variation.replace(\"_Up\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get fake contribution from FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def get_finetuned_score(data, model_path):\n",
    "    import onnx\n",
    "    import onnxruntime as ort\n",
    "\n",
    "    input_dict = {\n",
    "        \"highlevel\": data.loc[:, \"fj_ParT_hidNeuron000\":\"fj_ParT_hidNeuron127\"].values.astype(\"float32\"),\n",
    "    }\n",
    "\n",
    "    onnx_model = onnx.load(model_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "\n",
    "    ort_sess = ort.InferenceSession(\n",
    "        model_path,\n",
    "        providers=[\"AzureExecutionProvider\"],\n",
    "    )\n",
    "    outputs = ort_sess.run(None, input_dict)\n",
    "\n",
    "    return scipy.special.softmax(outputs[0], axis=1)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018, ele channel:\n",
      "FR_Nominal variation\n",
      "FR_stat_Up variation\n",
      "FR_stat_Down variation\n",
      "EWK_SF_Up variation\n",
      "EWK_SF_Down variation\n",
      "2018, mu channel:\n",
      "FR_Nominal variation\n",
      "FR_stat_Up variation\n",
      "FR_stat_Down variation\n",
      "EWK_SF_Up variation\n",
      "EWK_SF_Down variation\n",
      "2017, ele channel:\n",
      "FR_Nominal variation\n",
      "FR_stat_Up variation\n",
      "FR_stat_Down variation\n",
      "EWK_SF_Up variation\n",
      "EWK_SF_Down variation\n",
      "2017, mu channel:\n",
      "FR_Nominal variation\n",
      "FR_stat_Up variation\n",
      "FR_stat_Down variation\n",
      "EWK_SF_Up variation\n",
      "EWK_SF_Down variation\n",
      "2016, ele channel:\n",
      "FR_Nominal variation\n",
      "FR_stat_Up variation\n",
      "FR_stat_Down variation\n",
      "EWK_SF_Up variation\n",
      "EWK_SF_Down variation\n",
      "2016, mu channel:\n",
      "FR_Nominal variation\n",
      "FR_stat_Up variation\n",
      "FR_stat_Down variation\n",
      "EWK_SF_Up variation\n",
      "EWK_SF_Down variation\n",
      "2016APV, ele channel:\n",
      "FR_Nominal variation\n",
      "FR_stat_Up variation\n",
      "FR_stat_Down variation\n",
      "EWK_SF_Up variation\n",
      "EWK_SF_Down variation\n",
      "2016APV, mu channel:\n",
      "FR_Nominal variation\n",
      "FR_stat_Up variation\n",
      "FR_stat_Down variation\n",
      "EWK_SF_Up variation\n",
      "EWK_SF_Down variation\n"
     ]
    }
   ],
   "source": [
    "PR = {\n",
    "    \"ele\":     {\n",
    "        \"Barrel_allpt\": 0.793,\n",
    "        \"Endcap_allpt\": 0.737\n",
    "    },\n",
    "    \"mu\":     {\n",
    "        \"Barrel_allpt\": 0.948,\n",
    "        \"Endcap_allpt\": 0.941\n",
    "    },\n",
    "}\n",
    "\n",
    "ptbinning = {}\n",
    "ptbinning[\"ele\"] = [2000, 200, 160, 120, 30]\n",
    "ptbinning[\"mu\"] = [2000, 80, 60, 30]\n",
    "\n",
    "for year in years:\n",
    "    for ch in channels:\n",
    "#         if ch != \"mu\":\n",
    "#             continue        \n",
    "        print(f\"{year}, {ch} channel:\")\n",
    "\n",
    "#         outdir = f\"/Users/fmokhtar/projects/boostedhiggs/eos/hww/Dec20_hww_{year}\"\n",
    "#         indir = f\"/Users/fmokhtar/projects/boostedhiggs/eos/hww/Dec20_hww_uselooselep_{year}\"\n",
    "        \n",
    "        outdir = f\"/Users/fmokhtar/projects/boostedhiggs/eos/hww/Jun5_hww_{year}\"\n",
    "        indir = f\"/Users/fmokhtar/projects/boostedhiggs/eos/hww/Jun5_hww_uselooselep_{year}\"\n",
    "                \n",
    "        os.makedirs(f\"{outdir}/Fake\", exist_ok=True)\n",
    "\n",
    "        if ch == \"ele\":\n",
    "            if year == \"2018\":\n",
    "                l = glob.glob(f\"{indir}/EGamma*/outfiles/*_{ch}.parquet\")\n",
    "            else:\n",
    "                l = glob.glob(f\"{indir}/SingleElectron*/outfiles/*_{ch}.parquet\")\n",
    "        else:\n",
    "            l = glob.glob(f\"{indir}/SingleMuon*/outfiles/*_{ch}.parquet\")\n",
    "        \n",
    "        for variation in variations:\n",
    "#             if variation != \"FR_Nominal\":\n",
    "#                 continue\n",
    "            \n",
    "            print(variation, \"variation\")\n",
    "            data = pd.read_parquet(l)\n",
    "\n",
    "            data[\"THWW\"] = get_finetuned_score(data, \"../../weaver-core-dev/experiments_finetuning/v35_30/model.onnx\")\n",
    "\n",
    "            if ch == \"ele\":\n",
    "                Nt0 = (data[\"n_tight_electrons\"]==0)\n",
    "                Nt1 = (data[\"n_tight_electrons\"]==1)\n",
    "            else:\n",
    "                Nt0 = (data[\"n_tight_muons\"]==0)\n",
    "                Nt1 = (data[\"n_tight_muons\"]==1)\n",
    "\n",
    "            data[\"nominal\"] = 1            \n",
    "\n",
    "            for i in range(len(ptbinning[ch])-1):\n",
    "                high_pt = ptbinning[ch][i]\n",
    "                low_pt = ptbinning[ch][i+1]\n",
    "\n",
    "                msk_pt = (data[\"lep_pt\"] >= low_pt) & (data[\"lep_pt\"] < high_pt)\n",
    "\n",
    "                for j in range(len(etabinning)-1):\n",
    "\n",
    "                    if j == 0:\n",
    "                        pr = PR[ch][\"Barrel_allpt\"]\n",
    "                    else:\n",
    "                        pr = PR[ch][\"Endcap_allpt\"]\n",
    "\n",
    "                    low_eta = etabinning[j]\n",
    "                    high_eta = etabinning[j+1]\n",
    "\n",
    "                    msk_eta = (abs(data[\"lep_eta\"]) >= low_eta) & (abs(data[\"lep_eta\"]) < high_eta)\n",
    "\n",
    "                    w_Nt0 = (pr * FR[ch][variation][i,j]) / (pr - FR[ch][variation][i,j])\n",
    "                    w_Nt1 = (FR[ch][variation][i,j] * (pr-1)) / (pr - FR[ch][variation][i,j])\n",
    "                    \n",
    "                    data[\"nominal\"][msk_pt & msk_eta & Nt0] = w_Nt0\n",
    "                    data[\"nominal\"][msk_pt & msk_eta & Nt1] = w_Nt1\n",
    "\n",
    "                    data.to_parquet(f\"{outdir}/Fake/fake_{year}_{ch}_{variation}.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea-env",
   "language": "python",
   "name": "coffea-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
